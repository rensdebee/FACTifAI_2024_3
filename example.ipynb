{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility Study of “Studying How to Efficiently and Effectively Guide Models with Explanations”\n",
    "\n",
    "Description: This file is part of a project aiming to reproduce the study titled \"Studying How to Efficiently and \n",
    "Effectively Guide Models with Explanations.\" The project focuses on verifying the results and methodologies \n",
    "proposed in the original study, and potentially extending or refining the study's findings.\n",
    "\n",
    "Based on the code of orginal paper: https://github.com/sukrutrao/Model-Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For VOC2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data of VOC2007. The data is stored in the folder `datasets/VOC2007/`. The data is stored in the format of `.pt` file. We use the function `preprocess_voc2007.py` to load the data. Because this is run in a Jupyter Notebook, the `argspace` library is used to pass the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from datasets.VOC2007.preprocess import preprocess_voc2007\n",
    "\n",
    "data_root = \"datasets/VOC2007/\"\n",
    "split = \"train\"\n",
    "save_path = \"datasets/VOC2007/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"data_root\": data_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_voc2007(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from datasets.VOC2007.preprocess import preprocess_voc2007\n",
    "\n",
    "data_root = \"datasets/VOC2007/\"\n",
    "split = \"val\"\n",
    "save_path = \"datasets/VOC2007/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"data_root\": data_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_voc2007(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from datasets.VOC2007.preprocess import preprocess_voc2007\n",
    "\n",
    "data_root = \"datasets/VOC2007/\"\n",
    "split = \"test\"\n",
    "save_path = \"datasets/VOC2007/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"data_root\": data_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_voc2007(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For waterbirds\n",
    "\n",
    "Secondly, we load the data of waterbirds. The data is stored in the folder `datasets/WATERBIRDS/`. The data is stored in the format of `.pt` file. We use the function `preprocess_waterbirds.py` to load the data. Because this is run in a Jupyter Notebook, the `argspace` library is used to pass the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse  \n",
    "\n",
    "from datasets.WATERBIRDS.preprocess import preprocess_waterbirds\n",
    "\n",
    "bounding_boxes_path = \"./datasets/WATERBIRDS/bounding_boxes.txt\"\n",
    "waterbirds_dataset_root = \"./datasets/WATERBIRDS/waterbird_1.0_forest2water2/\"\n",
    "split = \"train\"\n",
    "save_path = \"./datasets/WATERBIRDS/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"bounding_boxes_path\": bounding_boxes_path,\n",
    "    \"waterbirds_dataset_root\": waterbirds_dataset_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_waterbirds(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from datasets.WATERBIRDS.preprocess import preprocess_waterbirds\n",
    "\n",
    "bounding_boxes_path = \"./datasets/WATERBIRDS/bounding_boxes.txt\"\n",
    "waterbirds_dataset_root = \"./datasets/WATERBIRDS/waterbird_1.0_forest2water2/\"\n",
    "split = \"val\"\n",
    "save_path = \"./datasets/WATERBIRDS/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"bounding_boxes_path\": bounding_boxes_path,\n",
    "    \"waterbirds_dataset_root\": waterbirds_dataset_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_waterbirds(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from datasets.WATERBIRDS.preprocess import preprocess_waterbirds\n",
    "\n",
    "bounding_boxes_path = \"./datasets/WATERBIRDS/bounding_boxes.txt\"\n",
    "waterbirds_dataset_root = \"./datasets/WATERBIRDS/waterbird_1.0_forest2water2/\"\n",
    "split = \"test\"\n",
    "save_path = \"./datasets/WATERBIRDS/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"bounding_boxes_path\": bounding_boxes_path,\n",
    "    \"waterbirds_dataset_root\": waterbirds_dataset_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_waterbirds(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "os.chdir(\"weights\")\n",
    "os.makedirs(\"bcos\", exist_ok=True)\n",
    "os.chdir(\"bcos\")\n",
    "\n",
    "url = \"https://nextcloud.mpi-klsb.mpg.de/index.php/s/3Yk6p86SBBFYSBN/download\"\n",
    "filename = \"resnet_50-f46c1a4159.pth\"\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the baseline model\n",
    "\n",
    "Train the baseline model using the training data for 2 epochs and a batch size of 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For VOC2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from train import main\n",
    "\n",
    "model_backbone = \"vanilla\"\n",
    "total_epochs = 2\n",
    "learning_rate = 1e-4\n",
    "log_path = \"./base_logs_demo\"\n",
    "save_path = \"./BASE_DEMO\"\n",
    "train_batch_size = 16\n",
    "dataset = \"VOC2007\"\n",
    "\n",
    "# Default values\n",
    "seed = 0\n",
    "model_path = None\n",
    "data_path = \"datasets/\"\n",
    "localization_loss_lambda = 1.0\n",
    "layer = \"Input\"\n",
    "localization_loss_fn = None\n",
    "attribution_method = None\n",
    "optimize_explanations = False\n",
    "min_fscore = -1\n",
    "pareto = False\n",
    "annotated_fraction = 1.0\n",
    "evaluation_frequency = 1\n",
    "eval_batch_size = 4\n",
    "box_dilation_percentage = 0\n",
    "pareto_metric = \"EPG_IOU\"\n",
    "\n",
    "args = {\n",
    "    \"model_backbone\": model_backbone,\n",
    "    \"total_epochs\": total_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"log_path\": log_path,\n",
    "    \"save_path\": save_path,\n",
    "    \"seed\": seed,\n",
    "    \"train_batch_size\": train_batch_size,\n",
    "    \"dataset\": dataset,\n",
    "    \"model_path\": model_path,\n",
    "    \"data_path\": data_path,\n",
    "    \"localization_loss_lambda\": localization_loss_lambda,\n",
    "    \"layer\": layer,\n",
    "    \"localization_loss_fn\": localization_loss_fn,\n",
    "    \"attribution_method\": attribution_method,\n",
    "    \"optimize_explanations\": optimize_explanations,\n",
    "    \"min_fscore\": min_fscore,\n",
    "    \"pareto\": pareto,\n",
    "    \"annotated_fraction\": annotated_fraction,\n",
    "    \"evaluation_frequency\": evaluation_frequency,\n",
    "    \"eval_batch_size\": eval_batch_size,\n",
    "    \"box_dilation_percentage\": box_dilation_percentage,\n",
    "    \"pareto_metric\": pareto_metric\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the fine-tuned model on the base model\n",
    "\n",
    "For the fine-tuned model, due to computational resource limitation, we only train on 2 epochs and a batch size of 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from train import main\n",
    "\n",
    "model_backbone = \"vanilla\"\n",
    "total_epochs = 2\n",
    "learning_rate = 1e-4\n",
    "log_path = \"./finetune_logs_demo\"\n",
    "save_path = \"./FT_DEMO\"\n",
    "train_batch_size = 16\n",
    "dataset = \"VOC2007\"\n",
    "\n",
    "model_path = \"./BASE_DEMO/VOC2007/vanilla_standard_attrNone_loclossNone_origNone_resnet50_lr0.0001_sll1.0_layerInput/model_checkpoint_f1_best.pt\"\n",
    "\n",
    "# Default values\n",
    "seed = 0\n",
    "data_path = \"datasets/\"\n",
    "localization_loss_lambda = 1e-3\n",
    "layer = \"Final\"\n",
    "localization_loss_fn = \"Energy\"\n",
    "attribution_method = \"IxG\"\n",
    "optimize_explanations = True\n",
    "min_fscore = -1\n",
    "pareto = True\n",
    "annotated_fraction = 1.0\n",
    "evaluation_frequency = 1\n",
    "eval_batch_size = 4\n",
    "box_dilation_percentage = 0\n",
    "pareto_metric = \"EPG_IOU\"\n",
    "\n",
    "args = {\n",
    "    \"model_backbone\": model_backbone,\n",
    "    \"total_epochs\": total_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"log_path\": log_path,\n",
    "    \"save_path\": save_path,\n",
    "    \"seed\": seed,\n",
    "    \"train_batch_size\": train_batch_size,\n",
    "    \"dataset\": dataset,\n",
    "    \"model_path\": model_path,\n",
    "    \"data_path\": data_path,\n",
    "    \"localization_loss_lambda\": localization_loss_lambda,\n",
    "    \"layer\": layer,\n",
    "    \"localization_loss_fn\": localization_loss_fn,\n",
    "    \"attribution_method\": attribution_method,\n",
    "    \"optimize_explanations\": optimize_explanations,\n",
    "    \"min_fscore\": min_fscore,\n",
    "    \"pareto\": pareto,\n",
    "    \"annotated_fraction\": annotated_fraction,\n",
    "    \"evaluation_frequency\": evaluation_frequency,\n",
    "    \"eval_batch_size\": eval_batch_size,\n",
    "    \"box_dilation_percentage\": box_dilation_percentage,\n",
    "    \"pareto_metric\": pareto_metric\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the fine-tuned model on the test set\n",
    "\n",
    "Evaluate the fine-tuned model on the test set and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import evaluation_function\n",
    "\n",
    "model_path = './FT_DEMO/VOC2007/vanilla_finetunedobjlocpareto_attrIxG_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.001_layerFinal/model_checkpoint_f1_best.pt'\n",
    "\n",
    "split = 'test'\n",
    "\n",
    "mode = 'bbs'\n",
    "\n",
    "dataset = 'VOC2007'\n",
    "\n",
    "# Create kwargs for evaluation function\n",
    "args = {'model_path': model_path,\n",
    "        'split': split,\n",
    "        'mode': mode,\n",
    "        'dataset': dataset}\n",
    "\n",
    "# Evaluate\n",
    "evaluation_function(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize the different attribution methods\n",
    "\n",
    "Visualize the different attribution methods on the test set. Due to computational resource limitation, we load the best model checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from visualize import visualize_fig9\n",
    "\n",
    "visualize_fig9(\n",
    "    [\n",
    "        \"BASE/VOC2007/bcos_standard_attrNone_loclossNone_origNone_resnet50_lr0.0001_sll1.0_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/VOC2007/bcos_finetunedobjlocpareto_attrBCos_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/VOC2007/bcos_finetunedobjlocpareto_attrBCos_loclossL1_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.01_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/VOC2007/bcos_finetunedobjlocpareto_attrBCos_loclossPPCE_origmodel_checkpoint_f1_best.pt_resnet50_lr0.001_sll0.001_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/VOC2007/bcos_finetunedobjlocpareto_attrBCos_loclossRRR_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll5e-05_layerInput/model_checkpoint_f1_best.pt\",\n",
    "    ],\n",
    "    last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualize the model with dilated bounding boxes\n",
    "\n",
    "To demonstrate the effect of dilated bounding boxes, we visualize the model with dilated bounding boxes. Due to computational resource limitation, we load in the pre-trained model and visualize the model with dilated bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from visualize import visualize_fig11\n",
    "\n",
    "visualize_fig11(\n",
    "    base_path=\"BASE/VOC2007/bcos_standard_attrNone_loclossNone_origNone_resnet50_lr0.0001_sll1.0_layerInput/model_checkpoint_f1_best.pt\",\n",
    "    energy_paths=[\n",
    "        \"FT/DIL/bcos_finetunedobjlocpareto_attrBCos_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/DIL/bcos_FT_dilated_attrBCos_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput_dil0.5/model_checkpoint_f1_best.pt\",\n",
    "    ],\n",
    "    L1_paths=[\n",
    "        \"FT/DIL/bcos_finetunedobjlocpareto_attrBCos_loclossL1_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/DIL/bcos_FT_dilated_attrBCos_loclossL1_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput_dil0.5/model_checkpoint_f1_best.pt\",\n",
    "    ],\n",
    "    last=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Show that the Pareto Front works\n",
    "\n",
    "To show that the Pareto Front works, we need to evaluate the model on the test set and calculate the Pareto Front. But due to computational resource limitation, we selected 6 model checkpoints from the fine-tuned model and evaluate them on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pareto_FT import pareto_demo\n",
    "\n",
    "bin_width=0.005,\n",
    "layer=\"Final\"\n",
    "data_split=\"test\"\n",
    "attribution_method=\"BCos\"\n",
    "eval_batch_size=4\n",
    "model_dir=\"./FT/VOC2007/bcos/fin/l1/bcos_finetunedobjlocpareto_attrBCos_loclossL1_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerFinal/pareto_front\"\n",
    "output_dir=\"./p_curves_demo/VOC2007/bcos/Final/L1\"\n",
    "\n",
    "pareto_demo(\n",
    "    bin_width=bin_width,\n",
    "    layer=layer,\n",
    "    data_split=data_split,\n",
    "    attribution_method=attribution_method,\n",
    "    eval_batch_size=eval_batch_size,\n",
    "    model_dir=model_dir,\n",
    "    output_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are shown in the following figure. We can see the distinction between the Pareto Front and the non-Pareto Front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from visualize import *\n",
    "\n",
    "root_folder = './p_curves_demo/VOC2007/bcos/Final/L1/pareto'\n",
    "data_f1_epg_pareto = utils.load_data_from_folders_with_npz_files(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "root_folder = './p_curves_demo/VOC2007/bcos/Final/L1/not_pareto'\n",
    "data_f1_epg_not_pareto = utils.load_data_from_folders_with_npz_files(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg_pareto['vanilla']['input']['baseline'],\n",
    "    l1_data=data_f1_epg_pareto['bcos']['final']['l1'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=(79, 81),\n",
    "    set_ylim=(50, 73),\n",
    "    hide_x_ticks=False,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"IxG\",\n",
    "    plot_demo_data=True,\n",
    "    demo_data=data_f1_epg_not_pareto['bcos']['final']['l1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Show the evaluation results of the fine-tuned model (Pareto front)\n",
    "\n",
    "In this section, we show the evaluation results of the fine-tuned model (Pareto front) on the test set. Because of computational resource limitation, we saved the evaluation results in a .npz file. The evaluation results are loaded from the .npz file  with the ```load_data_from_folders_with_npz_files``` function in ```utils.py``` and visualized with the ```plot_pareto_curve``` function in ```visualize.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from visualize import *\n",
    "\n",
    "root_folder = './p_curves/VOC2007'\n",
    "data_f1_epg = utils.load_data_from_folders_with_npz_files(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "x_lim_range = (65, 85)\n",
    "y_lim_range = (31, 90)\n",
    "step_size_xticks = 5\n",
    "step_size_yticks = 10\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg['vanilla']['input']['baseline'],\n",
    "    energy_data=data_f1_epg['vanilla']['input']['energy'],\n",
    "    l1_data=data_f1_epg['vanilla']['input']['l1'],\n",
    "    ppce_data=data_f1_epg['vanilla']['input']['ppce'],\n",
    "    rrr_data=data_f1_epg['vanilla']['input']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=True,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"IxG\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg['bcos']['input']['baseline'],\n",
    "    energy_data=data_f1_epg['bcos']['input']['energy'],\n",
    "    l1_data=data_f1_epg['bcos']['input']['l1'],\n",
    "    ppce_data=data_f1_epg['bcos']['input']['ppce'],\n",
    "    rrr_data=data_f1_epg['bcos']['input']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=True,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"B-cos\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg['vanilla']['final']['baseline'],\n",
    "    energy_data=data_f1_epg['vanilla']['final']['energy'],\n",
    "    l1_data=data_f1_epg['vanilla']['final']['l1'],\n",
    "    ppce_data=data_f1_epg['vanilla']['final']['ppce'],\n",
    "    rrr_data=data_f1_epg['vanilla']['final']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=False,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"IxG\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg['bcos']['final']['baseline'],\n",
    "    energy_data=data_f1_epg['bcos']['final']['energy'],\n",
    "    l1_data=data_f1_epg['bcos']['final']['l1'],\n",
    "    ppce_data=data_f1_epg['bcos']['final']['ppce'],\n",
    "    rrr_data=data_f1_epg['bcos']['final']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=(step_size_yticks),\n",
    "    hide_x_ticks=False,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"B-cos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath, max_depth=0):\n",
    "    for root, dirs, files in os.walk(startpath, topdown=True):\n",
    "        dirs.sort()  # Sort directories alphabetically\n",
    "        files.sort() # Sort files alphabetically\n",
    "\n",
    "        current_depth = root.count(os.sep) - startpath.count(os.sep)\n",
    "        \n",
    "        # Skip processing if current depth is beyond max_depth\n",
    "        if max_depth != 0 and current_depth > max_depth:\n",
    "            del dirs[:]\n",
    "            continue\n",
    "\n",
    "        # Print directories and .py files only at the specified depth\n",
    "        if current_depth == max_depth:\n",
    "            if root != startpath:\n",
    "                prefix = '│   ' * (current_depth - 1)\n",
    "                print(f\"{prefix}├── {os.path.basename(root)}\")\n",
    "\n",
    "            all_items = [f for f in dirs]\n",
    "            all_items += [f for f in files if f.endswith('.py')]\n",
    "\n",
    "            for index, item in enumerate(all_items):\n",
    "                if index == len(all_items) - 1:  # Last item\n",
    "                    subindent = '│   ' * current_depth + '└── '\n",
    "                else:\n",
    "                    subindent = '│   ' * current_depth + '├── '\n",
    "                print(f'{subindent}{item}')\n",
    "\n",
    "# Provide the path to the starting directory and max depth\n",
    "list_files('./', max_depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FACTifAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
