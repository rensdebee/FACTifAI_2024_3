{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility Study of “Studying How to Efficiently and Effectively Guide Models with Explanations”\n",
    "\n",
    "Description: This file is part of a project aiming to reproduce the study titled \"Studying How to Efficiently and \n",
    "Effectively Guide Models with Explanations.\" The project focuses on verifying the results and methodologies \n",
    "proposed in the original study, and potentially extending or refining the study's findings.\n",
    "\n",
    "Based on the code of orginal paper: https://github.com/sukrutrao/Model-Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the ImageNet Model Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Check if the xdnn directory exists and if the xfixup_resnet50_model_best.pth.tar exists\n",
    "if not os.path.exists(\"weights/xdnn/xfixup_resnet50_model_best.pth.tar\"):\n",
    "\n",
    "    # Check if the xdnn directory exists, create if it doesn't\n",
    "    if not os.path.exists(\"weights/xdnn\"):\n",
    "        os.makedirs(\"weights/xdnn\")\n",
    "\n",
    "    # Download the xfixup_resnet50_model_best.pth.tar\n",
    "    subprocess.run([\"wget\", \"-P\", \"weights/xdnn/\", \"https://download.visinf.tu-darmstadt.de/data/2021-neurips-fast-axiomatic-attribution/models/xfixup_resnet50_model_best.pth.tar\"])\n",
    "\n",
    "    # Change the current directory to the parent directory\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "# Check if the bcos directory exists and if the resnet_50-f46c1a4159.pth exists\n",
    "if not os.path.exists(\"weights/bcos/resnet_50-f46c1a4159.pth\"):\n",
    "\n",
    "    # Check if the bcos directory exists, create if it doesn't\n",
    "    if not os.path.exists(\"weights/bcos\"):\n",
    "        os.makedirs(\"weights/bcos\")\n",
    "\n",
    "    # Download the resnet_50-f46c1a4159.pth\n",
    "    subprocess.run([\"wget\", \"-O\", \"weights/bcos/resnet_50-f46c1a4159.pth\", \"https://nextcloud.mpi-klsb.mpg.de/index.php/s/3Yk6p86SBBFYSBN/download\"])\n",
    "\n",
    "    # Change the current directory to the parent directory\n",
    "    os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For VOC2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data of VOC2007. The data is stored in the folder `datasets/VOC2007/`. The data is stored in the format of `.pt` file. We use the function `preprocess_voc2007.py` to load the data. Because this is run in a Jupyter Notebook, the `argspace` library is used to pass the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "from datasets.VOC2007.preprocess import preprocess_voc2007\n",
    "\n",
    "data_root = \"datasets/VOC2007/\"\n",
    "split = \"train\"\n",
    "save_path = \"datasets/VOC2007/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"data_root\": data_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "# check if the .pt file already exists\n",
    "if os.path.exists(os.path.join(save_path, f\"{split}.pt\")):\n",
    "    \n",
    "    print(f\"Dataset {split} already exists.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    args = argparse.Namespace(**args)\n",
    "\n",
    "    preprocess_voc2007(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "from datasets.VOC2007.preprocess import preprocess_voc2007\n",
    "\n",
    "data_root = \"datasets/VOC2007/\"\n",
    "split = \"val\"\n",
    "save_path = \"datasets/VOC2007/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"data_root\": data_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "# check if the .pt file already exists\n",
    "if os.path.exists(os.path.join(save_path, f\"{split}.pt\")):\n",
    "    \n",
    "    print(f\"Dataset {split} already exists.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    args = argparse.Namespace(**args)\n",
    "\n",
    "    preprocess_voc2007(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "from datasets.VOC2007.preprocess import preprocess_voc2007\n",
    "\n",
    "data_root = \"datasets/VOC2007/\"\n",
    "split = \"test\"\n",
    "save_path = \"datasets/VOC2007/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"data_root\": data_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "# check if the .pt file already exists\n",
    "if os.path.exists(os.path.join(save_path, f\"{split}.pt\")):\n",
    "    \n",
    "    print(f\"Dataset {split} already exists.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    args = argparse.Namespace(**args)\n",
    "\n",
    "    preprocess_voc2007(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "from datasets.VOC2007.preprocess import preprocess_voc2007\n",
    "\n",
    "data_root = \"datasets/VOC2007/\"\n",
    "split = \"trainval\"\n",
    "save_path = \"datasets/VOC2007/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"data_root\": data_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "# check if the .pt file already exists\n",
    "if os.path.exists(os.path.join(save_path, f\"{split}.pt\")):\n",
    "    \n",
    "    print(f\"Dataset {split} already exists.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    args = argparse.Namespace(**args)\n",
    "\n",
    "    preprocess_voc2007(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For waterbirds\n",
    "\n",
    "Secondly, we load the data of waterbirds. The data is stored in the folder `datasets/WATERBIRDS/`. The data is stored in the format of `.pt` file. We use the function `preprocess_waterbirds.py` to load the data. Because this is run in a Jupyter Notebook, the `argspace` library is used to pass the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse  \n",
    "\n",
    "from datasets.WATERBIRDS.preprocess import preprocess_waterbirds\n",
    "\n",
    "bounding_boxes_path = \"./datasets/WATERBIRDS/bounding_boxes.txt\"\n",
    "waterbirds_dataset_root = \"./datasets/WATERBIRDS/waterbird_1.0_forest2water2/\"\n",
    "split = \"train\"\n",
    "save_path = \"./datasets/WATERBIRDS/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"bounding_boxes_path\": bounding_boxes_path,\n",
    "    \"waterbirds_dataset_root\": waterbirds_dataset_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_waterbirds(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from datasets.WATERBIRDS.preprocess import preprocess_waterbirds\n",
    "\n",
    "bounding_boxes_path = \"./datasets/WATERBIRDS/bounding_boxes.txt\"\n",
    "waterbirds_dataset_root = \"./datasets/WATERBIRDS/waterbird_1.0_forest2water2/\"\n",
    "split = \"val\"\n",
    "save_path = \"./datasets/WATERBIRDS/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"bounding_boxes_path\": bounding_boxes_path,\n",
    "    \"waterbirds_dataset_root\": waterbirds_dataset_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_waterbirds(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from datasets.WATERBIRDS.preprocess import preprocess_waterbirds\n",
    "\n",
    "bounding_boxes_path = \"./datasets/WATERBIRDS/bounding_boxes.txt\"\n",
    "waterbirds_dataset_root = \"./datasets/WATERBIRDS/waterbird_1.0_forest2water2/\"\n",
    "split = \"test\"\n",
    "save_path = \"./datasets/WATERBIRDS/processed/\"\n",
    "\n",
    "args = {\n",
    "    \"bounding_boxes_path\": bounding_boxes_path,\n",
    "    \"waterbirds_dataset_root\": waterbirds_dataset_root,\n",
    "    \"split\": split,\n",
    "    \"save_path\": save_path\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "preprocess_waterbirds(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the baseline model\n",
    "\n",
    "Train the baseline model using the training data for 2 epochs and a batch size of 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For VOC2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from train import main\n",
    "\n",
    "model_backbone = \"vanilla\"\n",
    "total_epochs = 2\n",
    "learning_rate = 1e-4\n",
    "log_path = \"./base_logs_demo\"\n",
    "save_path = \"./BASE_DEMO\"\n",
    "train_batch_size = 16\n",
    "dataset = \"VOC2007\"\n",
    "\n",
    "# Default values\n",
    "seed = 0\n",
    "model_path = None\n",
    "data_path = \"datasets/\"\n",
    "localization_loss_lambda = 1.0\n",
    "layer = \"Input\"\n",
    "localization_loss_fn = None\n",
    "attribution_method = None\n",
    "optimize_explanations = False\n",
    "min_fscore = -1\n",
    "pareto = False\n",
    "annotated_fraction = 1.0\n",
    "evaluation_frequency = 1\n",
    "eval_batch_size = 4\n",
    "box_dilation_percentage = 0\n",
    "pareto_metric = \"EPG_IOU\"\n",
    "\n",
    "args = {\n",
    "    \"model_backbone\": model_backbone,\n",
    "    \"total_epochs\": total_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"log_path\": log_path,\n",
    "    \"save_path\": save_path,\n",
    "    \"seed\": seed,\n",
    "    \"train_batch_size\": train_batch_size,\n",
    "    \"dataset\": dataset,\n",
    "    \"model_path\": model_path,\n",
    "    \"data_path\": data_path,\n",
    "    \"localization_loss_lambda\": localization_loss_lambda,\n",
    "    \"layer\": layer,\n",
    "    \"localization_loss_fn\": localization_loss_fn,\n",
    "    \"attribution_method\": attribution_method,\n",
    "    \"optimize_explanations\": optimize_explanations,\n",
    "    \"min_fscore\": min_fscore,\n",
    "    \"pareto\": pareto,\n",
    "    \"annotated_fraction\": annotated_fraction,\n",
    "    \"evaluation_frequency\": evaluation_frequency,\n",
    "    \"eval_batch_size\": eval_batch_size,\n",
    "    \"box_dilation_percentage\": box_dilation_percentage,\n",
    "    \"pareto_metric\": pareto_metric\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For waterbirds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Since Waterbird uses ImageNet pretrained weigths as a baseline model no code is needed to create a baseline model for waterbirds*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the fine-tuned model on the base model\n",
    "\n",
    "For the fine-tuned model, due to computational resource limitation, we only train on 2 epochs and a batch size of 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For VOC2007:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from train import main\n",
    "\n",
    "model_backbone = \"vanilla\"\n",
    "total_epochs = 2\n",
    "learning_rate = 1e-4\n",
    "log_path = \"./finetune_logs_demo\"\n",
    "save_path = \"./FT_DEMO\"\n",
    "train_batch_size = 16\n",
    "dataset = \"VOC2007\"\n",
    "\n",
    "model_path = \"./BASE_DEMO/VOC2007/vanilla_standard_attrNone_loclossNone_origNone_resnet50_lr0.0001_sll1.0_layerInput/model_checkpoint_f1_best.pt\"\n",
    "\n",
    "# Default values\n",
    "seed = 0\n",
    "data_path = \"datasets/\"\n",
    "localization_loss_lambda = 1e-3\n",
    "layer = \"Final\"\n",
    "localization_loss_fn = \"Energy\"\n",
    "attribution_method = \"IxG\"\n",
    "optimize_explanations = True\n",
    "min_fscore = -1\n",
    "pareto = True\n",
    "annotated_fraction = 1.0\n",
    "evaluation_frequency = 1\n",
    "eval_batch_size = 4\n",
    "box_dilation_percentage = 0\n",
    "pareto_metric = \"EPG_IOU\"\n",
    "\n",
    "args = {\n",
    "    \"model_backbone\": model_backbone,\n",
    "    \"total_epochs\": total_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"log_path\": log_path,\n",
    "    \"save_path\": save_path,\n",
    "    \"seed\": seed,\n",
    "    \"train_batch_size\": train_batch_size,\n",
    "    \"dataset\": dataset,\n",
    "    \"model_path\": model_path,\n",
    "    \"data_path\": data_path,\n",
    "    \"localization_loss_lambda\": localization_loss_lambda,\n",
    "    \"layer\": layer,\n",
    "    \"localization_loss_fn\": localization_loss_fn,\n",
    "    \"attribution_method\": attribution_method,\n",
    "    \"optimize_explanations\": optimize_explanations,\n",
    "    \"min_fscore\": min_fscore,\n",
    "    \"pareto\": pareto,\n",
    "    \"annotated_fraction\": annotated_fraction,\n",
    "    \"evaluation_frequency\": evaluation_frequency,\n",
    "    \"eval_batch_size\": eval_batch_size,\n",
    "    \"box_dilation_percentage\": box_dilation_percentage,\n",
    "    \"pareto_metric\": pareto_metric\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Waterbirds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from train import main\n",
    "\n",
    "model_backbone = \"bcos\"\n",
    "total_epochs = 2\n",
    "learning_rate = 1e-5\n",
    "log_path = \"./base_logs_demo\"\n",
    "save_path = \"./FT_DEMO\"\n",
    "train_batch_size = 16\n",
    "dataset = \"WATERBIRDS\"\n",
    "\n",
    "# Default values\n",
    "seed = 0\n",
    "model_path = None\n",
    "data_path = \"datasets/\"\n",
    "localization_loss_lambda = 1.0\n",
    "layer = \"Input\"\n",
    "localization_loss_fn = None\n",
    "attribution_method = None\n",
    "optimize_explanations = False\n",
    "min_fscore = -1\n",
    "pareto = False\n",
    "annotated_fraction = 1.0\n",
    "evaluation_frequency = 1\n",
    "eval_batch_size = 4\n",
    "box_dilation_percentage = 0\n",
    "pareto_metric = \"EPG_IOU\"\n",
    "\n",
    "args = {\n",
    "    \"model_backbone\": model_backbone,\n",
    "    \"total_epochs\": total_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"log_path\": log_path,\n",
    "    \"save_path\": save_path,\n",
    "    \"seed\": seed,\n",
    "    \"train_batch_size\": train_batch_size,\n",
    "    \"dataset\": dataset,\n",
    "    \"model_path\": model_path,\n",
    "    \"data_path\": data_path,\n",
    "    \"localization_loss_lambda\": localization_loss_lambda,\n",
    "    \"layer\": layer,\n",
    "    \"localization_loss_fn\": localization_loss_fn,\n",
    "    \"attribution_method\": attribution_method,\n",
    "    \"optimize_explanations\": optimize_explanations,\n",
    "    \"min_fscore\": min_fscore,\n",
    "    \"pareto\": pareto,\n",
    "    \"annotated_fraction\": annotated_fraction,\n",
    "    \"evaluation_frequency\": evaluation_frequency,\n",
    "    \"eval_batch_size\": eval_batch_size,\n",
    "    \"box_dilation_percentage\": box_dilation_percentage,\n",
    "    \"pareto_metric\": pareto_metric\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the fine-tuned model on the test set\n",
    "\n",
    "Evaluate the fine-tuned model on the test set and save the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For VOC2007:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import evaluation_function\n",
    "\n",
    "model_path = './FT_DEMO/VOC2007/vanilla_finetunedobjlocpareto_attrIxG_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.001_layerFinal/model_checkpoint_f1_best.pt'\n",
    "\n",
    "split = 'test'\n",
    "\n",
    "mode = 'bbs'\n",
    "\n",
    "dataset = 'VOC2007'\n",
    "\n",
    "# Create kwargs for evaluation function\n",
    "args = {'model_path': model_path,\n",
    "        'split': split,\n",
    "        'mode': mode,\n",
    "        'dataset': dataset}\n",
    "\n",
    "# Evaluate\n",
    "evaluation_function(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Waterbirds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import evaluation_function\n",
    "\n",
    "model_path = './FT_DEMO/WATERBIRDS/bcos_standard_attrNone_loclossNone_origNone_resnet50_lr1e-05_sll1.0_layerInput/model_checkpoint_f1_best.pt'\n",
    "\n",
    "split = 'test'\n",
    "\n",
    "mode = 'bbs'\n",
    "\n",
    "dataset = 'WATERBIRDS'\n",
    "\n",
    "# Create kwargs for evaluation function\n",
    "args = {'model_path': model_path,\n",
    "        'split': split,\n",
    "        'mode': mode,\n",
    "        'dataset': dataset}\n",
    "\n",
    "# Evaluate\n",
    "evaluation_function(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize the different attribution methods\n",
    "\n",
    "Visualize the different attribution methods on the test set. Due to computational resource limitation, we load the best model checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from visualize import visualize_fig9\n",
    "\n",
    "visualize_fig9(\n",
    "    [\n",
    "        \"BASE/VOC2007/bcos_standard_attrNone_loclossNone_origNone_resnet50_lr0.0001_sll1.0_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/VOC2007/bcos_finetunedobjlocpareto_attrBCos_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/VOC2007/bcos_finetunedobjlocpareto_attrBCos_loclossL1_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.01_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/VOC2007/bcos_finetunedobjlocpareto_attrBCos_loclossPPCE_origmodel_checkpoint_f1_best.pt_resnet50_lr0.001_sll0.001_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/VOC2007/bcos_finetunedobjlocpareto_attrBCos_loclossRRR_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll5e-05_layerInput/model_checkpoint_f1_best.pt\",\n",
    "    ],\n",
    "    last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualize the model with dilated bounding boxes\n",
    "\n",
    "To demonstrate the effect of dilated bounding boxes, we visualize the model with dilated bounding boxes. Due to computational resource limitation, we load in the pre-trained model and visualize the model with dilated bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from visualize import visualize_fig11\n",
    "\n",
    "visualize_fig11(\n",
    "    base_path=\"BASE/VOC2007/bcos_standard_attrNone_loclossNone_origNone_resnet50_lr0.0001_sll1.0_layerInput/model_checkpoint_f1_best.pt\",\n",
    "    energy_paths=[\n",
    "        \"FT/DIL/bcos_finetunedobjlocpareto_attrBCos_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/DIL/bcos_FT_dilated_attrBCos_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput_dil0.5/model_checkpoint_f1_best.pt\",\n",
    "    ],\n",
    "    L1_paths=[\n",
    "        \"FT/DIL/bcos_finetunedobjlocpareto_attrBCos_loclossL1_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput/model_checkpoint_f1_best.pt\",\n",
    "        \"FT/DIL/bcos_FT_dilated_attrBCos_loclossL1_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerInput_dil0.5/model_checkpoint_f1_best.pt\",\n",
    "    ],\n",
    "    last=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Show that the Pareto Front works\n",
    "\n",
    "To show that the Pareto Front works, we need to evaluate the model on the test set and calculate the Pareto Front. But due to computational resource limitation, we selected 6 model checkpoints from the fine-tuned model (see the given path) and evaluate them on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pareto_FT import pareto_demo\n",
    "\n",
    "bin_width=0.005,\n",
    "layer=\"Final\"\n",
    "data_split=\"test\"\n",
    "attribution_method=\"BCos\"\n",
    "eval_batch_size=4\n",
    "model_dir=\"./FT/VOC2007/bcos/fin/l1/bcos_finetunedobjlocpareto_attrBCos_loclossL1_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.005_layerFinal/pareto_front\"\n",
    "output_dir=\"./p_curves_demo/VOC2007/bcos/Final/L1/pareto\"\n",
    "\n",
    "pareto_demo(\n",
    "    bin_width=bin_width,\n",
    "    layer=layer,\n",
    "    data_split=data_split,\n",
    "    attribution_method=attribution_method,\n",
    "    eval_batch_size=eval_batch_size,\n",
    "    model_dir=model_dir,\n",
    "    output_dir=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are shown in the following figure. We can see the distinction between the Pareto Front and the non-Pareto Front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from visualize import *\n",
    "\n",
    "root_folder = './p_curves_demo/VOC2007/bcos/Final/L1/pareto'\n",
    "data_f1_epg_pareto = utils.load_data_from_folders_with_npz_files(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "root_folder = './p_curves_demo/VOC2007/bcos/Final/L1/not_pareto'\n",
    "data_f1_epg_not_pareto = utils.load_data_from_folders_with_npz_files(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg_pareto['vanilla']['input']['baseline'],\n",
    "    l1_data=data_f1_epg_pareto['bcos']['final']['l1'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=(79, 81),\n",
    "    set_ylim=(50, 73),\n",
    "    hide_x_ticks=False,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"IxG\",\n",
    "    plot_demo_data=True,\n",
    "    demo_data=data_f1_epg_not_pareto['bcos']['final']['l1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Show the results from the additional experiment (fairness.py), which looks at each class individually and downloads a .csv file with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "model_pathBase = \"./BASE/VOC2007/bcos_standard_attrNone_loclossNone_origNone_resnet50_lr0.0001_sll1.0_layerInput/model_checkpoint_f1_best.pt\"\n",
    "model_pathFN50 = \"./FT/VOC2007/vanilla_finetunedobjlocpareto_attrIxG_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.001_layerInput/model_checkpoint_f1_best.pt\"\n",
    "model_pathFNbest = \"./FT/VOC2007/vanilla_finetunedobjlocpareto_attrIxG_loclossEnergy_origmodel_checkpoint_f1_best.pt_resnet50_lr0.0001_sll0.001_layerInput/model_checkpoint_final_50.pt\"\n",
    "dataset = \"VOC2007\"\n",
    "split = \"test\"\n",
    "metric = \"BB-Loc\"\n",
    "\n",
    "from fairness import main\n",
    "\n",
    "args = {\n",
    "    \"model_pathBase\": model_pathBase,\n",
    "    \"model_pathFN50\": model_pathFN50,\n",
    "    \"model_pathFNbest\": model_pathFNbest,\n",
    "    \"dataset\": dataset,\n",
    "    \"split\": split,\n",
    "    \"metric\": metric\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results from the additional experiment in a dataframe. Due to computational resource limitation, we load in the pre-trained model and show the results from the additional experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class-name</th>\n",
       "      <th>num-samples</th>\n",
       "      <th>bl-means</th>\n",
       "      <th>ft50-means</th>\n",
       "      <th>percentage50_diff</th>\n",
       "      <th>ftbest-means</th>\n",
       "      <th>percentagebest_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aeroplane</td>\n",
       "      <td>tensor(205)</td>\n",
       "      <td>57.7</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-18.5</td>\n",
       "      <td>41.1</td>\n",
       "      <td>-28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>tensor(250)</td>\n",
       "      <td>55.4</td>\n",
       "      <td>53.8</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>54.1</td>\n",
       "      <td>-2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bird</td>\n",
       "      <td>tensor(289)</td>\n",
       "      <td>42.8</td>\n",
       "      <td>42.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>41.6</td>\n",
       "      <td>-2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boat</td>\n",
       "      <td>tensor(176)</td>\n",
       "      <td>42.2</td>\n",
       "      <td>31.3</td>\n",
       "      <td>-25.8</td>\n",
       "      <td>31.3</td>\n",
       "      <td>-25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bottle</td>\n",
       "      <td>tensor(240)</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bus</td>\n",
       "      <td>tensor(183)</td>\n",
       "      <td>59.9</td>\n",
       "      <td>52.9</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>52.9</td>\n",
       "      <td>-11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>car</td>\n",
       "      <td>tensor(775)</td>\n",
       "      <td>48.8</td>\n",
       "      <td>44.8</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat</td>\n",
       "      <td>tensor(332)</td>\n",
       "      <td>65.9</td>\n",
       "      <td>63.5</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chair</td>\n",
       "      <td>tensor(545)</td>\n",
       "      <td>25.6</td>\n",
       "      <td>28.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>-3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cow</td>\n",
       "      <td>tensor(127)</td>\n",
       "      <td>54.6</td>\n",
       "      <td>48.5</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>-18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>diningtable</td>\n",
       "      <td>tensor(247)</td>\n",
       "      <td>47.9</td>\n",
       "      <td>52.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>-10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dog</td>\n",
       "      <td>tensor(433)</td>\n",
       "      <td>59.4</td>\n",
       "      <td>54.9</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>horse</td>\n",
       "      <td>tensor(279)</td>\n",
       "      <td>65.4</td>\n",
       "      <td>54.8</td>\n",
       "      <td>-16.2</td>\n",
       "      <td>59.5</td>\n",
       "      <td>-9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>motorbike</td>\n",
       "      <td>tensor(233)</td>\n",
       "      <td>62.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>-11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>person</td>\n",
       "      <td>tensor(2097)</td>\n",
       "      <td>45.6</td>\n",
       "      <td>46.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>42.4</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pottedplant</td>\n",
       "      <td>tensor(254)</td>\n",
       "      <td>30.8</td>\n",
       "      <td>38.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>38.4</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sheep</td>\n",
       "      <td>tensor(98)</td>\n",
       "      <td>49.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-10.4</td>\n",
       "      <td>38.4</td>\n",
       "      <td>-21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sofa</td>\n",
       "      <td>tensor(355)</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train</td>\n",
       "      <td>tensor(259)</td>\n",
       "      <td>62.9</td>\n",
       "      <td>50.1</td>\n",
       "      <td>-20.4</td>\n",
       "      <td>46.6</td>\n",
       "      <td>-25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tvmonitor</td>\n",
       "      <td>tensor(255)</td>\n",
       "      <td>27.8</td>\n",
       "      <td>29.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>27.7</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class-name   num-samples  bl-means  ft50-means  percentage50_diff  \\\n",
       "0     aeroplane   tensor(205)      57.7        47.0              -18.5   \n",
       "1       bicycle   tensor(250)      55.4        53.8               -2.9   \n",
       "2          bird   tensor(289)      42.8        42.6               -0.5   \n",
       "3          boat   tensor(176)      42.2        31.3              -25.8   \n",
       "4        bottle   tensor(240)      16.9        19.7               16.8   \n",
       "5           bus   tensor(183)      59.9        52.9              -11.5   \n",
       "6           car   tensor(775)      48.8        44.8               -8.3   \n",
       "7           cat   tensor(332)      65.9        63.5               -3.6   \n",
       "8         chair   tensor(545)      25.6        28.4               10.6   \n",
       "9           cow   tensor(127)      54.6        48.5              -11.0   \n",
       "10  diningtable   tensor(247)      47.9        52.5                9.5   \n",
       "11          dog   tensor(433)      59.4        54.9               -7.6   \n",
       "12        horse   tensor(279)      65.4        54.8              -16.2   \n",
       "13    motorbike   tensor(233)      62.5        59.5               -4.9   \n",
       "14       person  tensor(2097)      45.6        46.4                1.8   \n",
       "15  pottedplant   tensor(254)      30.8        38.8               25.8   \n",
       "16        sheep    tensor(98)      49.1        44.0              -10.4   \n",
       "17         sofa   tensor(355)      52.0        57.5               10.5   \n",
       "18        train   tensor(259)      62.9        50.1              -20.4   \n",
       "19    tvmonitor   tensor(255)      27.8        29.3                5.5   \n",
       "\n",
       "    ftbest-means  percentagebest_diff  \n",
       "0           41.1                -28.7  \n",
       "1           54.1                 -2.4  \n",
       "2           41.6                 -2.7  \n",
       "3           31.3                -25.9  \n",
       "4           17.3                  2.5  \n",
       "5           52.9                -11.5  \n",
       "6           35.5                -27.4  \n",
       "7           64.0                 -2.8  \n",
       "8           24.8                 -3.3  \n",
       "9           44.4                -18.6  \n",
       "10          42.8                -10.8  \n",
       "11          51.4                -13.5  \n",
       "12          59.5                 -9.1  \n",
       "13          55.5                -11.2  \n",
       "14          42.4                 -7.0  \n",
       "15          38.4                 24.4  \n",
       "16          38.4                -21.8  \n",
       "17          51.0                 -2.0  \n",
       "18          46.6                -25.9  \n",
       "19          27.7                 -0.2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"./csv_files/VOC2007_BB-Loc_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Show the evaluation results of the fine-tuned model (Pareto front)\n",
    "\n",
    "In this section, we show the evaluation results of the fine-tuned model (Pareto front) on the test set. Because of computational resource limitation, we saved the evaluation results in .npz files. The evaluation results are loaded from the .npz files  with the ```load_data_from_folders_with_npz_files``` function in ```utils.py``` and visualized with the ```plot_pareto_curve``` function in ```visualize.py```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The plots for figure 1 from our reproducibility study are shown below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from visualize import *\n",
    "\n",
    "root_folder = './p_curves/VOC2007'\n",
    "data_f1_epg = utils.load_data_from_folders_with_npz_files(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "x_lim_range = (65, 85)\n",
    "y_lim_range = (31, 90)\n",
    "step_size_xticks = 5\n",
    "step_size_yticks = 10\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg['vanilla']['input']['baseline'],\n",
    "    energy_data=data_f1_epg['vanilla']['input']['energy'],\n",
    "    l1_data=data_f1_epg['vanilla']['input']['l1'],\n",
    "    ppce_data=data_f1_epg['vanilla']['input']['ppce'],\n",
    "    rrr_data=data_f1_epg['vanilla']['input']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=True,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"IxG\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg['bcos']['input']['baseline'],\n",
    "    energy_data=data_f1_epg['bcos']['input']['energy'],\n",
    "    l1_data=data_f1_epg['bcos']['input']['l1'],\n",
    "    ppce_data=data_f1_epg['bcos']['input']['ppce'],\n",
    "    rrr_data=data_f1_epg['bcos']['input']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=True,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"B-cos\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg['vanilla']['final']['baseline'],\n",
    "    energy_data=data_f1_epg['vanilla']['final']['energy'],\n",
    "    l1_data=data_f1_epg['vanilla']['final']['l1'],\n",
    "    ppce_data=data_f1_epg['vanilla']['final']['ppce'],\n",
    "    rrr_data=data_f1_epg['vanilla']['final']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=False,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"IxG\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_epg['bcos']['final']['baseline'],\n",
    "    energy_data=data_f1_epg['bcos']['final']['energy'],\n",
    "    l1_data=data_f1_epg['bcos']['final']['l1'],\n",
    "    ppce_data=data_f1_epg['bcos']['final']['ppce'],\n",
    "    rrr_data=data_f1_epg['bcos']['final']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=(step_size_yticks),\n",
    "    hide_x_ticks=False,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"B-cos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The plots for figure 2 from our reproducibility study are shown below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from visualize import *\n",
    "\n",
    "root_folder = './p_curves/VOC2007'\n",
    "data_f1_iou = utils.load_data_from_folders_with_npz_files(root_folder, metrics=('f_score', 'iou_score'))\n",
    "\n",
    "x_lim_range = (65, 85)\n",
    "y_lim_range = (11, 60)\n",
    "step_size_xticks = 5\n",
    "step_size_yticks = 10\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_iou['vanilla']['final']['baseline'],\n",
    "    energy_data=data_f1_iou['vanilla']['final']['energy'],\n",
    "    l1_data=data_f1_iou['vanilla']['final']['l1'],\n",
    "    ppce_data=data_f1_iou['vanilla']['final']['ppce'],\n",
    "    rrr_data=data_f1_iou['vanilla']['final']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='IoU Score (%)',\n",
    "    title='',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim = x_lim_range,\n",
    "    set_ylim = y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"IxG\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_f1_iou['bcos']['final']['baseline'],\n",
    "    energy_data=data_f1_iou['bcos']['final']['energy'],\n",
    "    l1_data=data_f1_iou['bcos']['final']['l1'],\n",
    "    ppce_data=data_f1_iou['bcos']['final']['ppce'],\n",
    "    rrr_data=data_f1_iou['bcos']['final']['rrr'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='IoU Score (%)',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim = x_lim_range,\n",
    "    set_ylim = y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"B-cos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The plots for figure 4 from our reproducibility study are shown below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from visualize import *\n",
    "\n",
    "root_folder = './p_c_ann'\n",
    "data_limited_ann_f1_epg = utils.load_data_from_folders_with_npz_files_with_limited_ann(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "x_lim_range = (75, 81)\n",
    "y_lim_range = (41, 90)\n",
    "step_size_xticks = 2\n",
    "step_size_yticks = 10\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_limited_ann_f1_epg['bcos']['lim0.01']['baseline'],\n",
    "    energy_data=data_limited_ann_f1_epg['bcos']['lim0.01']['energy'],\n",
    "    l1_data=data_limited_ann_f1_epg['bcos']['lim0.01']['l1'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    figsize=(8, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_limited_ann_f1_epg['bcos']['lim0.1']['baseline'],\n",
    "    energy_data=data_limited_ann_f1_epg['bcos']['lim0.1']['energy'],\n",
    "    l1_data=data_limited_ann_f1_epg['bcos']['lim0.1']['l1'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    figsize=(8, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"\")\n",
    "\n",
    "plot_pareto_curve(\n",
    "    baseline_data=data_limited_ann_f1_epg['bcos']['lim1.0']['baseline'],\n",
    "    energy_data=data_limited_ann_f1_epg['bcos']['lim1.0']['energy'],\n",
    "    l1_data=data_limited_ann_f1_epg['bcos']['lim1.0']['l1'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    figsize=(8, 4),\n",
    "    set_xlim=x_lim_range,\n",
    "    set_ylim=y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20,\n",
    "    attribution_method=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The plots for figure 5 from our reproducibility study are shown below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from visualize import *    \n",
    "\n",
    "root_folder = './p_curves/VOC2007'\n",
    "data_speed_up_f1_epg = utils.load_data_from_folders_with_npz_files(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "x_lim_range = (74, 81)\n",
    "y_lim_range = (41, 90)\n",
    "step_size_xticks = 2\n",
    "step_size_yticks = 10\n",
    "\n",
    "plot_pareto_curve_speed_up(\n",
    "    baseline_data=data_speed_up_f1_epg['bcos']['input']['baseline'],\n",
    "    energy_data_input_layer=data_speed_up_f1_epg['bcos']['input']['energy'],\n",
    "    energy_data=data_speed_up_f1_epg['bcos']['mid2']['energy'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    speed_up_text='Speed-up: 1.25x',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim = x_lim_range,\n",
    "    set_ylim = y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20)\n",
    "\n",
    "plot_pareto_curve_speed_up(\n",
    "    baseline_data=data_speed_up_f1_epg['bcos']['input']['baseline'],\n",
    "    energy_data_input_layer=data_speed_up_f1_epg['bcos']['input']['energy'],\n",
    "    energy_data=data_speed_up_f1_epg['bcos']['final']['energy'],\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    speed_up_text='Speed-up: 2.0x',\n",
    "    figsize=(10, 4),\n",
    "    set_xlim = x_lim_range,\n",
    "    set_ylim = y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The plots for figure 6 from our reproducibility study are shown below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from visualize import *    \n",
    "\n",
    "root_folder = './p_c_dil'\n",
    "data_dilation_f1_epg = utils.load_data_from_folders_with_npz_files_with_dilation(root_folder, metrics=('f_score', 'bb_score'))\n",
    "\n",
    "x_lim_range = (75, 81)\n",
    "y_lim_range = (41, 80)\n",
    "step_size_xticks = 2\n",
    "step_size_yticks = 10\n",
    "\n",
    "plot_pareto_curve_dilation(\n",
    "    baseline_data=data_dilation_f1_epg['bcos']['dil0']['baseline'],\n",
    "    data_0=data_dilation_f1_epg['bcos']['dil0']['energy'],\n",
    "    data_01=data_dilation_f1_epg['bcos']['dil0.1']['energy'],\n",
    "    data_025=data_dilation_f1_epg['bcos']['dil0.25']['energy'],\n",
    "    data_05=data_dilation_f1_epg['bcos']['dil0.5']['energy'],\n",
    "    data_0_not_pareto=data_dilation_f1_epg['bcos']['dil0_not_pareto']['energy'],\n",
    "    data_01_not_pareto=data_dilation_f1_epg['bcos']['dil0.1_not_pareto']['energy'],\n",
    "    data_025_not_pareto=data_dilation_f1_epg['bcos']['dil0.25_not_pareto']['energy'],\n",
    "    data_05_not_pareto=data_dilation_f1_epg['bcos']['dil0.5_not_pareto']['energy'],\n",
    "    loss='Energy',\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    save_path='./images/fig_10_voc2007_bcos_resnet50_dilation_loss_energy_f1_epg_pareto_curve.png',\n",
    "    figsize=(8, 6),\n",
    "    set_xlim = x_lim_range,\n",
    "    set_ylim = y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=True,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20)\n",
    "\n",
    "plot_pareto_curve_dilation(\n",
    "    baseline_data=data_dilation_f1_epg['bcos']['dil0']['baseline'],\n",
    "    data_0=data_dilation_f1_epg['bcos']['dil0']['l1'],\n",
    "    data_01=data_dilation_f1_epg['bcos']['dil0.1']['l1'],\n",
    "    data_025=data_dilation_f1_epg['bcos']['dil0.25']['l1'],\n",
    "    data_05=data_dilation_f1_epg['bcos']['dil0.5']['l1'],\n",
    "    data_0_not_pareto=data_dilation_f1_epg['bcos']['dil0_not_pareto']['l1'],\n",
    "    data_01_not_pareto=data_dilation_f1_epg['bcos']['dil0.1_not_pareto']['l1'],\n",
    "    data_025_not_pareto=data_dilation_f1_epg['bcos']['dil0.25_not_pareto']['l1'],\n",
    "    data_05_not_pareto=data_dilation_f1_epg['bcos']['dil0.5_not_pareto']['l1'],\n",
    "    loss='L1',\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='EPG Score (%)',\n",
    "    save_path='./images/fig_10_voc2007_bcos_resnet50_dilation_loss_l1_f1_epg_pareto_curve.png',\n",
    "    figsize=(8, 6),\n",
    "    set_xlim = x_lim_range,\n",
    "    set_ylim = y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=True,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20)\n",
    "\n",
    "root_folder = './p_c_dil'\n",
    "data_dilation_f1_epg = utils.load_data_from_folders_with_npz_files_with_dilation(root_folder, metrics=('f_score', 'adapt_iou_score'))\n",
    "\n",
    "x_lim_range = (75, 81)\n",
    "y_lim_range = (11, 35)\n",
    "step_size_xticks = 2\n",
    "step_size_yticks = 10\n",
    "\n",
    "plot_pareto_curve_dilation(\n",
    "    baseline_data=data_dilation_f1_epg['bcos']['dil0']['baseline'],\n",
    "    data_0=data_dilation_f1_epg['bcos']['dil0']['energy'],\n",
    "    data_01=data_dilation_f1_epg['bcos']['dil0.1']['energy'],\n",
    "    data_025=data_dilation_f1_epg['bcos']['dil0.25']['energy'],\n",
    "    data_05=data_dilation_f1_epg['bcos']['dil0.5']['energy'],\n",
    "    data_0_not_pareto=data_dilation_f1_epg['bcos']['dil0_not_pareto']['energy'],\n",
    "    data_01_not_pareto=data_dilation_f1_epg['bcos']['dil0.1_not_pareto']['energy'],\n",
    "    data_025_not_pareto=data_dilation_f1_epg['bcos']['dil0.25_not_pareto']['energy'],\n",
    "    data_05_not_pareto=data_dilation_f1_epg['bcos']['dil0.5_not_pareto']['energy'],\n",
    "    loss='Energy',\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='Adapted IoU Score (%)',\n",
    "    save_path='./images/fig_10_voc2007_bcos_resnet50_dilation_loss_energy_f1_adapt_iou_pareto_curve.png',\n",
    "    figsize=(8, 6),\n",
    "    set_xlim = x_lim_range,\n",
    "    set_ylim = y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=False,\n",
    "    hide_y_ticks=False,\n",
    "    fontsize=20)\n",
    "\n",
    "plot_pareto_curve_dilation(\n",
    "    baseline_data=data_dilation_f1_epg['bcos']['dil0']['baseline'],\n",
    "    data_0=data_dilation_f1_epg['bcos']['dil0']['l1'],\n",
    "    data_01=data_dilation_f1_epg['bcos']['dil0.1']['l1'],\n",
    "    data_025=data_dilation_f1_epg['bcos']['dil0.25']['l1'],\n",
    "    data_05=data_dilation_f1_epg['bcos']['dil0.5']['l1'],\n",
    "    data_0_not_pareto=data_dilation_f1_epg['bcos']['dil0_not_pareto']['l1'],\n",
    "    data_01_not_pareto=data_dilation_f1_epg['bcos']['dil0.1_not_pareto']['l1'],\n",
    "    data_025_not_pareto=data_dilation_f1_epg['bcos']['dil0.25_not_pareto']['l1'],\n",
    "    data_05_not_pareto=data_dilation_f1_epg['bcos']['dil0.5_not_pareto']['l1'],\n",
    "    loss='L1',\n",
    "    x_label='F1 Score (%)',\n",
    "    y_label='Adapted IoU Score (%)',\n",
    "    save_path='./images/fig_10_voc2007_bcos_resnet50_dilation_loss_l1_f1_adapt_iou_pareto_curve.png',\n",
    "    figsize=(8, 6),\n",
    "    set_xlim = x_lim_range,\n",
    "    set_ylim = y_lim_range,\n",
    "    step_size_xticks=step_size_xticks,\n",
    "    step_size_yticks=step_size_yticks,\n",
    "    hide_x_ticks=False,\n",
    "    hide_y_ticks=True,\n",
    "    fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FACTifAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
